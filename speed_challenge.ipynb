{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speed_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPOPZp3HxrDrtvC+7rINmjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diggs1711/comma-ai-speed-challenge/blob/master/speed_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwCp3FVfM4Au",
        "colab_type": "code",
        "outputId": "35c74da7-5ad1-4d4e-f0d1-2727b374a797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from cv2 import VideoCapture\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import math\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUrpshliPZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "drive_path = Path('/content/drive/My Drive/comma_ai_speed_challenge/speedchallenge-master/data/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPxE9HBNmVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_vals = np.array(pd.read_fwf(drive_path/'train.txt', header=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDnl-8TSu9sO",
        "colab_type": "code",
        "outputId": "7f39299a-c611-40e3-df4e-aebf008127e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(f\"mean {train_vals.mean()}\")\n",
        "print(f\"max {train_vals.max()}\")\n",
        "print(f\"std {train_vals.std()}\")\n",
        "print(f\"min {train_vals.min()}\")\n",
        "\n",
        "idx = int(len(train_vals) / 2)\n",
        "print()\n",
        "print(\"*** First half of video ****\")\n",
        "first_half = train_vals[:idx]\n",
        "print(f\"mean 1st {first_half.mean()}\")\n",
        "print(f\"max 1st {first_half.max()}\")\n",
        "print(f\"std 1st {first_half.std()}\")\n",
        "print(f\"min 1st {first_half.min()}\")\n",
        "\n",
        "print()\n",
        "print(\"*** Second half of video ****\")\n",
        "second_half = train_vals[idx:]\n",
        "print(f\"mean 2nd {second_half.mean()}\")\n",
        "print(f\"max 2nd {second_half.max()}\")\n",
        "print(f\"std 2nd {second_half.std()}\")\n",
        "print(f\"min 2nd {second_half.min()}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean 12.183181660441177\n",
            "max 28.130404\n",
            "std 8.206561706745727\n",
            "min 0.0\n",
            "\n",
            "*** First half of video ****\n",
            "mean 1st 18.66717958362745\n",
            "max 1st 28.130404\n",
            "std 1st 5.883530076403356\n",
            "min 1st 0.0\n",
            "\n",
            "*** Second half of video ****\n",
            "mean 2nd 5.699183737254902\n",
            "max 2nd 14.890168\n",
            "std 2nd 3.9993656743963695\n",
            "min 2nd 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngHfnZosUbw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numberOfFrame = 20400\n",
        "fps = 20\n",
        "cropped_image_height = 100\n",
        "cropped_image_width = 440"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P8sBQLXON8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load video frame by frame\n",
        "# cap = VideoCapture(str(drive_path/'train.mp4'))\n",
        "# i = 0\n",
        "# video_frames = []\n",
        "\n",
        "# while i < numberOfFrame:\n",
        "#   ret_val, frame = cap.read()\n",
        "#   cropped_image = frame[200:200+cropped_image_height,100:100+cropped_image_width, 2]\n",
        "#   video_frames.append(np.array(cropped_image))\n",
        "#   i = i + 1\n",
        "\n",
        "# cap.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U3qHXWL5WRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# video_frames = np.array(video_frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EuCZWt290jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save(str(drive_path/'video_frames'), video_frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aH9pkXs9_Yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_frames = np.load(str(drive_path/'video_frames.npy')) / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ctSGqXQezCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunk_video(data, target_data=None):\n",
        "  chunk_size = 100\n",
        "  result = []\n",
        "  target = []\n",
        "  i = 1\n",
        "  while i < len(data):\n",
        "    if i % chunk_size == 0:\n",
        "      result.append(data[i-chunk_size:i])\n",
        "      if target_data.any():\n",
        "        target.append(target_data[i-chunk_size:i])\n",
        "    i = i + 1\n",
        "\n",
        "  return result, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMIbRH5E2a3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = chunk_video(video_frames, train_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV7WpSgk2zql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation sets\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "valid_idx =  180\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
        "\n",
        "X_valid = X_train[valid_idx:]\n",
        "y_valid = y_train[valid_idx:]\n",
        "\n",
        "X_train = X_train[:valid_idx]\n",
        "y_train = y_train[:valid_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMZUoE62WodP",
        "colab_type": "code",
        "outputId": "984c17ff-c04f-4607-e5ab-9e36f3ce7389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del video_frames, train_vals;\n",
        "gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-ClkPhFZhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[..., np.newaxis]\n",
        "y_train = y_train\n",
        "\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "y_valid = y_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ7MZachSZr7",
        "colab_type": "code",
        "outputId": "e3f120bf-7210-4c49-caa4-95e54e9681da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180, 100, 100, 440, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06XmgWdRLQRT",
        "colab_type": "code",
        "outputId": "d5e6fdae-0b4c-4662-c0ba-9a8090fa117a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoQ0Nff63EI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09355d4f-fd3c-40c7-fed4-2100c7fa12d3"
      },
      "source": [
        "from keras.layers import Dense, Flatten, TimeDistributed, SimpleRNN, LSTM, Bidirectional, BatchNormalization, Conv2D, Dropout, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, concatenate, Reshape\n",
        "from keras.models import Sequential\n",
        "from keras import Model, Input\n",
        "import keras\n",
        "\n",
        "def build_model():\n",
        "  img_input = Input(shape=(None, cropped_image_height, cropped_image_width, 1))\n",
        "\n",
        "  x = TimeDistributed(Conv2D(16, 3, activation='relu'))(img_input)\n",
        "  x = TimeDistributed(BatchNormalization())(x)\n",
        "  x = TimeDistributed(GlobalMaxPooling2D())(x)\n",
        "\n",
        "  x = TimeDistributed(Dense(100, activation='relu'))(x)\n",
        "  x = Bidirectional(LSTM(4, return_sequences=True))(x)\n",
        "  x = Bidirectional(LSTM(4, return_sequences=True))(x)\n",
        "  x = TimeDistributed(Dense(20, activation='relu'))(x)\n",
        "\n",
        "  x = TimeDistributed(Dense(1, activation='relu'))(x)\n",
        "  \n",
        "  mod = Model(inputs=[img_input], outputs=x)\n",
        "  mod.compile('adam', 'mse')\n",
        "  return mod"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5HqXsh1YQXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "817372fd-532b-4a25-ade6-72c3d49636a3"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, 100, 440, 1) 0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 98, 438, 16) 160       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, None, 98, 438, 16) 64        \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, None, 100)         1700      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 8)           3360      \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 8)           416       \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, None, 20)          180       \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, None, 1)           21        \n",
            "=================================================================\n",
            "Total params: 5,901\n",
            "Trainable params: 5,869\n",
            "Non-trainable params: 32\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU1BvdkR6KaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = shuffle(X_train, y_train, random_state=42)\n",
        "X_val, y_val = shuffle(X_valid, y_valid, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pW5X8mCJsD-",
        "colab_type": "code",
        "outputId": "06dce510-da8c-468c-ceeb-7b39973e941b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "history = model.fit(\n",
        "    X,\n",
        "    y, \n",
        "    epochs=200,\n",
        "    batch_size=1,\n",
        "    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 180 samples, validate on 23 samples\n",
            "Epoch 1/200\n",
            "180/180 [==============================] - 158s 879ms/step - loss: 170.7253 - val_loss: 97.5046\n",
            "Epoch 2/200\n",
            "180/180 [==============================] - 150s 832ms/step - loss: 78.8513 - val_loss: 79.3212\n",
            "Epoch 3/200\n",
            "180/180 [==============================] - 149s 827ms/step - loss: 66.7621 - val_loss: 83.7779\n",
            "Epoch 4/200\n",
            "166/180 [==========================>...] - ETA: 11s - loss: 67.2847"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOsEVrQaKfkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_video_and_save_to_drive(filename, numberOfFrames):\n",
        "  # load video frame by frame\n",
        "  cap = VideoCapture(str(drive_path/filename))\n",
        "  i = 0\n",
        "  video_frames = []\n",
        "\n",
        "  while i < numberOfFrames:\n",
        "    ret_val, frame = cap.read()\n",
        "    cropped_image = frame[200:200+cropped_image_height,100:100+cropped_image_width, 2]\n",
        "    video_frames.append(np.array(cropped_image))\n",
        "    i = i + 1\n",
        "\n",
        "  print(\"processed finished\")\n",
        "  video_frames = np.array(video_frames)\n",
        "  print(\"Saving...\")\n",
        "  np.save(str(drive_path/f'frames-{filename}'), video_frames)\n",
        "  cap.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwcraLgn9iU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "968f7e6a-591f-46c0-c89b-b0958fb10755"
      },
      "source": [
        "load_video_and_save_to_drive('test.mp4', 10798)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed finished\n",
            "Saving...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m4EOu8foCLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_video_frames = np.load(str(drive_path/'frames-test.mp4.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jncRkaN3pJr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67e379fb-c6dc-42ca-8f20-db5e82a93c06"
      },
      "source": [
        "test_video_frames.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10798, 100, 440)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiRYX_QUphxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_video_frames = test_video_frames[np.newaxis, ..., np.newaxis] / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhUABOW2pKyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "d71ca73b-a738-4b9a-c5a9-14dd4b0bdf62"
      },
      "source": [
        "predictions = model.predict(test_video_frames[:500])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-7e0125d753b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[10798,16,98,438] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node time_distributed_9/convolution (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_10535]\n\nFunction call stack:\nkeras_scratch_graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Go2GzOrxP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2fe2b697-1e76-4210-e30c-cfdfb7061122"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.770994],\n",
              "       [18.333986],\n",
              "       [19.05152 ],\n",
              "       ...,\n",
              "       [14.621207],\n",
              "       [14.47956 ],\n",
              "       [14.278064]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57egu0icFcEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87ad4975-bd13-44c8-d607-1ea404819af7"
      },
      "source": [
        "train_vals.min()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcALUsFepQnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da4681a4-633f-4b32-d6f9-ff9c37c33967"
      },
      "source": [
        "predictions.min()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.986187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vw5akhSppVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f019c3-861c-48b7-b02e-c1673dc65486"
      },
      "source": [
        "predictions.max()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.80058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL9uOBCHp5t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8387ad0f-d6e0-4204-8a02-29a61b725cb2"
      },
      "source": [
        "predictions.mean()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.727596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E6v8CPcp8CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}